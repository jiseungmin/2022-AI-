{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 10\n",
    "\n",
    "(x_train, y_train), (x_test2, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28 * 28)\n",
    "x_test = x_test2.reshape(x_test2.shape[0], 28 * 28)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, nb_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=784, units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.fit(x_train, y_train, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test.shape[0]-1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "evaluation = tf.model.evaluate(x_test, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  CNN\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, y_train, x_test, y_test = train_test_split(train_x, target, test_size=0.3, random_state=0)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "x_test.size\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 65\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=65, units=1024, activation='leaky_relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=1024, activation='leaky_relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=65, activation='sigmoid'))\n",
    "tf.model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "tf.model.fit(x_train, x_test, epochs=training_epochs)\n",
    "random.seed(777)  # for reproducibility\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "nb_classes = 65\n",
    "\n",
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(input_dim=65, units=1024, activation='leaky_relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=1024, activation='leaky_relu'))\n",
    "tf.model.add(tf.keras.layers.Dense(units=nb_classes, activation='softmax'))\n",
    "\n",
    "tf.model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate), metrics=['accuracy'])\n",
    "tf.model.summary()\n",
    "\n",
    "tf.model.fit(x_train, x_test2, batch_size=batch_size, epochs=training_epochs)\n",
    "\n",
    "# predict 10 random hand-writing data\n",
    "y_predicted = tf.model.predict(x_test2)\n",
    "for x in range(0, 10):\n",
    "    random_index = random.randint(0, x_test2.shape[0]-1)\n",
    "    print(\"index: \", random_index,\n",
    "          \"actual y: \", np.argmax(y_test[random_index]),\n",
    "          \"predicted y: \", np.argmax(y_predicted[random_index]))\n",
    "\n",
    "# evaluate test set\n",
    "evaluation = tf.model.evaluate(x_test2, y_test)\n",
    "print('loss: ', evaluation[0])\n",
    "print('accuracy', evaluation[1])\n",
    "# 기타 등등\n",
    "# 레이블 인코딩\n",
    "# LabelEncoder 객체 생성 후  fit( )과 transform( ) 적용\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(a)\n",
    "labels = encoder.transform(a)\n",
    "print(labels)\n",
    "labels = labels.reshape(-1,1)\n",
    "print(labels)\n",
    "test[\"country\"] = labels\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "print(oh_labels.toarray())\n",
    "oh_labels.shape\n",
    "oh_labels = oh_labels.toarray()\n",
    "oh_labels = pd.DataFrame(oh_labels)\n",
    "oh_labels.columns = oh_encoder.get_feature_names()\n",
    "oh_labels.head()\n",
    "oh_labels = pd.concat([test[\"Q1\"], oh_labels], axis = 1)\n",
    "oh_labels\n",
    "test = test.drop(columns = ['Q1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f05e964b4d2e4afbb91fe932de86bd0523d55968cb2083dd8663aabd8c2c6a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
