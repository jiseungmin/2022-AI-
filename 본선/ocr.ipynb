{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import natsort \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train/train_00001.png</td>\n",
       "      <td>골목미용실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train/train_00002.png</td>\n",
       "      <td>한성부동산</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train/train_00003.png</td>\n",
       "      <td>홍라운지</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train/train_00004.png</td>\n",
       "      <td>모단걸응접실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train/train_00005.png</td>\n",
       "      <td>씨앗양식</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img_path    text\n",
       "0  ./train/train_00001.png   골목미용실\n",
       "1  ./train/train_00002.png   한성부동산\n",
       "2  ./train/train_00003.png    홍라운지\n",
       "3  ./train/train_00004.png  모단걸응접실\n",
       "4  ./train/train_00005.png    씨앗양식"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('open/test.csv')\n",
    "df2 = pd.read_csv(\"open/train.csv\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "file_path = 'open/train'\n",
    "file_names = os.listdir(file_path)\n",
    "file_names = natsort.natsorted(file_names)\n",
    "file_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import unlink\n",
    "\n",
    "same_name = []\n",
    "for f in os.listdir(file_path):\n",
    "    if 'train_' in f:\n",
    "        same_name.append(f)\n",
    "len(same_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 한글라벨링\n",
    "i = 0\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = os.path.join(\"/Users/jiseungmin/Desktop/AIContest/traindata\", df2['text'][i]+\".png\")\n",
    "    i+=1\n",
    "    os.rename(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiseungmin/Desktop/AIContest/ocr.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m file_names \u001b[39m=\u001b[39m natsort\u001b[39m.\u001b[39mnatsorted(file_names)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m12160\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   src\u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m/Users/jiseungmin/Desktop/AIContest/traindata/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mfile_names[[i]], cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   \u001b[39mif\u001b[39;00m src \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mImage load failed!\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not list"
     ]
    }
   ],
   "source": [
    "import natsort \n",
    "\n",
    "file_path = 'traindata'\n",
    "file_names = os.listdir(file_path)\n",
    "file_names = natsort.natsorted(file_names)\n",
    "\n",
    "for i in range(0,12160):\n",
    "  src= cv2.imread(\"/Users/jiseungmin/Desktop/AIContest/traindata/\"+file_names[[i]], cv2.IMREAD_COLOR)\n",
    "  if src is None:\n",
    "    print('Image load failed!')\n",
    "    exit(1)\n",
    "  result = cv2.cvtColor(src, cv2.COLOR_RGB2GRAY)\n",
    "  result = cv2.resize(result,(256,256))\n",
    "  cv2.imwrite('/Users/jiseungmin/Desktop/AIContest/3/'+file_names[i],result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  9507\n",
      "Number of labels found:  12159\n",
      "Number of unique characters:  1105\n",
      "Characters present:  [' ', '*', '0', '1', '2', '4', '5', '7', 'X', '_', 'x', 'ㅁ', 'ㅇ', 'ㅈ', 'ㅎ', '가', '각', '간', '갈', '감', '갑', '갓', '갔', '강', '같', '개', '객', '갤', '걀', '거', '걱', '건', '걷', '걸', '검', '겁', '것', '겅', '게', '겐', '겔', '겠', '겨', '격', '견', '결', '겹', '겼', '경', '곁', '계', '고', '곡', '곤', '곧', '골', '곰', '곱', '곳', '공', '과', '곽', '관', '광', '괘', '괜', '괴', '교', '구', '국', '군', '굴', '굽', '굿', '궁', '궈', '권', '귀', '귓', '규', '귝', '균', '그', '극', '근', '글', '금', '급', '긋', '긍', '기', '긴', '긷', '길', '김', '깃', '깊', '까', '깐', '깔', '깜', '깥', '깨', '꺼', '껍', '께', '꼬', '꼭', '꼰', '꼴', '꼼', '꽁', '꽂', '꽃', '꾸', '꾼', '꿀', '꿈', '꿔', '뀐', '끄', '끈', '끌', '끓', '끔', '끝', '끼', '나', '낙', '낚', '난', '날', '남', '납', '낫', '낭', '낮', '낯', '낳', '내', '낵', '낸', '냄', '냈', '냉', '냐', '냠', '냥', '너', '넌', '널', '넓', '넘', '넙', '넝', '넣', '네', '넥', '넬', '넷', '녀', '년', '념', '녕', '노', '녹', '논', '놀', '농', '높', '놓', '놔', '뇌', '뇨', '뇽', '누', '눈', '눔', '뉴', '느', '는', '늘', '늙', '능', '니', '닉', '닌', '닐', '님', '닙', '닛', '닝', '다', '닥', '단', '닫', '달', '닭', '닮', '담', '답', '닷', '당', '대', '댁', '댄', '댕', '더', '덕', '던', '덟', '덤', '덩', '덮', '데', '덴', '델', '뎀', '뎃', '뎅', '도', '독', '돈', '돌', '돔', '동', '돼', '되', '된', '될', '됩', '두', '둑', '둔', '둘', '둠', '둥', '뒤', '뒷', '듀', '드', '득', '든', '듣', '들', '듦', '듬', '듯', '등', '디', '딕', '딘', '딜', '딥', '딧', '딩', '따', '딱', '딴', '딸', '땅', '때', '땡', '떙', '떠', '떡', '떤', '떨', '떳', '떻', '떼', '또', '똘', '뚜', '뚝', '뚫', '뚱', '뛰', '뜨', '뜰', '뜸', '뜻', '띠', '라', '락', '란', '랄', '람', '랍', '랐', '랑', '래', '랙', '랜', '램', '랩', '랫', '랬', '랭', '략', '량', '러', '럭', '런', '럴', '럼', '럽', '럿', '렁', '렇', '레', '렉', '렌', '렐', '렘', '렙', '렛', '려', '력', '련', '렬', '렵', '령', '례', '로', '록', '론', '롤', '롬', '롭', '롯', '롱', '뢰', '료', '룡', '루', '룩', '룸', '룹', '룻', '류', '륜', '률', '륨', '르', '른', '를', '름', '릇', '릉', '리', '릭', '린', '릴', '림', '립', '릿', '링', '마', '막', '만', '많', '말', '맑', '맘', '맙', '맛', '망', '맞', '매', '맥', '맨', '맴', '맵', '맹', '맺', '머', '먹', '먼', '멀', '멈', '멋', '멍', '메', '멘', '멜', '멧', '며', '면', '멸', '명', '몇', '모', '목', '몬', '몰', '몸', '못', '몽', '묘', '무', '묵', '문', '묻', '물', '뭄', '뭉', '뭐', '뭔', '뮈', '뮤', '므', '미', '믹', '민', '믿', '밀', '밌', '밍', '및', '바', '박', '밖', '반', '받', '발', '밝', '밤', '밥', '밧', '방', '밭', '배', '백', '밴', '밸', '뱃', '뱅', '버', '번', '벌', '범', '법', '벗', '벚', '베', '벡', '벤', '벧', '벨', '벼', '벽', '변', '별', '볍', '병', '보', '복', '볶', '본', '볼', '봄', '봇', '봉', '봐', '봤', '뵙', '부', '북', '분', '불', '붉', '붐', '붓', '붕', '붙', '뷔', '뷰', '브', '븐', '블', '비', '빅', '빈', '빌', '빔', '빗', '빙', '빛', '빠', '빡', '빨', '빵', '빼', '뻐', '뻔', '뻘', '뻬', '뼈', '뽀', '뽁', '뽈', '뽑', '뽕', '뿌', '쁘', '쁜', '쁠', '쁨', '삘', '사', '삭', '산', '살', '삶', '삼', '삽', '상', '새', '색', '샌', '샐', '샘', '생', '샤', '샨', '샬', '샵', '샷', '샹', '샾', '서', '석', '선', '설', '섬', '섭', '섯', '성', '세', '섹', '센', '셀', '셉', '셋', '셔', '션', '셜', '셨', '셰', '셸', '소', '속', '손', '솔', '솜', '솝', '솟', '송', '솥', '쇄', '쇠', '쇼', '숍', '수', '숙', '순', '술', '숨', '숫', '숭', '숯', '숲', '숴', '쉐', '쉬', '쉴', '쉼', '쉽', '쉿', '슈', '슉', '슐', '스', '슨', '슬', '슴', '습', '승', '시', '식', '신', '실', '싫', '심', '십', '싯', '싱', '싶', '싸', '싼', '쌀', '쌈', '쌍', '쌤', '써', '썬', '썰', '썸', '썹', '쎄', '쎈', '쎼', '쏘', '쏠', '쏭', '쑝', '쓰', '쓴', '쓸', '씀', '씨', '씩', '씬', '씹', '씻', '씽', '아', '악', '안', '않', '알', '앓', '암', '압', '앗', '았', '앙', '앞', '애', '액', '앤', '앰', '앵', '야', '약', '얀', '얄', '양', '어', '억', '언', '얻', '얼', '엄', '업', '없', '엇', '었', '엉', '엌', '에', '엑', '엔', '엘', '엠', '엣', '여', '역', '엮', '연', '열', '염', '엽', '엿', '였', '영', '옆', '예', '옙', '옛', '오', '옥', '온', '올', '옮', '옳', '옴', '옵', '옷', '옻', '와', '왁', '완', '왓', '왔', '왕', '왜', '외', '요', '욕', '용', '우', '욱', '운', '울', '움', '웃', '웅', '워', '원', '월', '웠', '웨', '웰', '웹', '위', '윈', '윌', '윗', '윙', '유', '육', '윤', '율', '융', '으', '은', '을', '음', '응', '의', '이', '익', '인', '일', '읽', '잃', '임', '입', '잇', '있', '잉', '잊', '잎', '자', '작', '잔', '잖', '잘', '잠', '잡', '장', '재', '잭', '잼', '쟁', '쟈', '저', '적', '전', '절', '점', '접', '정', '제', '젝', '젠', '젤', '젬', '져', '젼', '졌', '조', '족', '존', '졸', '좀', '좁', '종', '좋', '좌', '죄', '죠', '주', '죽', '준', '줄', '줍', '중', '줘', '쥐', '쥬', '즈', '즉', '즌', '즐', '즘', '즙', '증', '지', '직', '진', '짇', '질', '짐', '집', '짓', '징', '짚', '짜', '짝', '짧', '짬', '짱', '째', '쩐', '쩡', '쪽', '쫄', '쫌', '쭈', '쭌', '쯤', '찌', '찜', '찢', '차', '착', '찬', '찮', '찰', '참', '찹', '찻', '창', '찾', '채', '책', '챌', '챔', '챙', '처', '척', '천', '철', '첨', '첩', '첫', '청', '체', '첸', '쳐', '초', '촌', '촛', '총', '촬', '최', '쵸', '추', '축', '춘', '출', '춤', '춧', '충', '취', '츄', '츠', '측', '층', '치', '칙', '친', '칠', '칡', '침', '칭', '카', '칵', '칸', '칼', '캇', '캉', '캐', '캔', '캘', '캠', '캡', '캣', '캬', '커', '컨', '컬', '컴', '컵', '컷', '케', '켄', '켈', '켐', '켑', '켓', '켜', '코', '콕', '콘', '콜', '콤', '콩', '쾌', '쿄', '쿠', '쿡', '쿤', '쿨', '쿱', '퀘', '퀴', '퀵', '퀸', '퀼', '큐', '큘', '크', '큰', '클', '큼', '키', '킥', '킨', '킬', '킴', '킹', '타', '탁', '탄', '탈', '탉', '탐', '탑', '탕', '태', '택', '탠', '탭', '터', '턱', '턴', '털', '텀', '텅', '테', '텍', '텐', '텔', '템', '토', '톡', '톤', '톨', '톰', '통', '퇴', '투', '툰', '툴', '퉁', '튀', '튜', '튤', '튬', '트', '특', '튼', '틀', '틈', '티', '틱', '틴', '틸', '팀', '팅', '파', '팍', '판', '팔', '팜', '팝', '팡', '팥', '패', '팩', '팬', '팰', '팽', '퍼', '펀', '펌', '펍', '페', '펙', '펜', '펠', '펫', '편', '평', '폐', '포', '폭', '폰', '폴', '폼', '표', '푸', '풀', '품', '풋', '풍', '퓨', '프', '픈', '플', '픔', '피', '픽', '핀', '필', '핌', '핍', '핏', '핑', '하', '학', '한', '할', '함', '합', '핫', '항', '해', '핵', '핸', '햄', '햇', '했', '행', '향', '햬', '허', '헌', '험', '헛', '헝', '헤', '헥', '헨', '헬', '헸', '혀', '혁', '현', '혈', '혐', '협', '형', '혜', '호', '혹', '혼', '홀', '홈', '홍', '화', '확', '환', '활', '황', '회', '획', '횟', '효', '후', '훈', '훔', '훙', '훠', '휘', '휴', '휼', '흉', '흐', '흑', '흔', '흘', '흠', '흡', '흥', '희', '흰', '히', '힌', '힐', '힘']\n"
     ]
    }
   ],
   "source": [
    "# Path to the data directory\n",
    "data_dir = Path(\"3\")\n",
    "img_labels = pd.read_csv(\"open/train.csv\")\n",
    "\n",
    "# Get list of all the images\n",
    "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
    "labels = img_labels.text.to_list()\n",
    "characters = set(char for label in labels for char in label)\n",
    "characters = sorted(list(characters))\n",
    "\n",
    "print(\"Number of images found: \", len(images))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "print(\"Number of unique characters: \", len(characters))\n",
    "print(\"Characters present: \", characters)\n",
    "\n",
    "# Batch size for training and validation\n",
    "batch_size = 4\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "\n",
    "# Factor by which the image is going to be downsampled\n",
    "# by the convolutional blocks. We will be using two\n",
    "# convolution blocks and each block will have\n",
    "# a pooling layer which downsample the features by a factor of 2.\n",
    "# Hence total downsampling factor would be 4.\n",
    "downsample_factor = 2\n",
    "\n",
    "# Maximum length of any captcha in the dataset\n",
    "max_length = max([len(label) for label in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping characters to integers\n",
    "char_to_num = layers.StringLookup(\n",
    "    vocabulary=list(characters), mask_token=None\n",
    ")\n",
    "\n",
    "# Mapping integers back to original characters\n",
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), mask_token=None, invert=True\n",
    ")\n",
    "\n",
    "\n",
    "def split_data(images, labels, train_size=0.9, shuffle=True):\n",
    "    # 1. Get the total size of the dataset\n",
    "    size = len(images)\n",
    "    # 2. Make an indices array and shuffle it, if required\n",
    "    indices = np.arange(size)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(indices)\n",
    "    # 3. Get the size of training samples\n",
    "    train_samples = int(size * train_size)\n",
    "    # 4. Split data into training and validation sets\n",
    "    x_train, y_train = images[indices[:train_samples]], labels[indices[:train_samples]]\n",
    "    x_valid, y_valid = images[indices[train_samples:]], labels[indices[train_samples:]]\n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "# Splitting data into training and validation sets\n",
    "x_train, x_valid, y_train, y_valid = split_data(np.array(images), np.array(labels))\n",
    "\n",
    "\n",
    "def encode_single_sample(img_path, label):\n",
    "    # 1. Read image\n",
    "    img = tf.io.read_file(img_path)\n",
    "    # 2. Decode and convert to grayscale\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    # 3. Convert to float32 in [0, 1] range\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # 4. Resize to the desired size\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    # 5. Transpose the image because we want the time\n",
    "    # dimension to correspond to the width of the image.\n",
    "    img = tf.transpose(img, perm=[1, 0, 2])\n",
    "    # 6. Map the characters in label to numbers\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    # 7. Return a dict as our model is expecting two inputs\n",
    "    return {\"image\": img, \"label\": label}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = (\n",
    "    train_dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n",
    "validation_dataset = (\n",
    "    validation_dataset.map(\n",
    "        encode_single_sample, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [2], [batch]: [3] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiseungmin/Desktop/AIContest/ocr.ipynb 셀 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m batch \u001b[39m=\u001b[39m  train_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     images \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [2], [batch]: [3] [Op:IteratorGetNext]"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, ax = plt.subplots(4, 4, figsize=(10, 5))\n",
    "\n",
    "batch =  train_dataset.take(1)\n",
    "\n",
    "for batch in train_dataset.take(1):\n",
    "    images = batch[\"image\"]\n",
    "    labels = batch[\"label\"]\n",
    "    for i in range(batch_size):\n",
    "        img = (images[i] * 255).numpy().astype(\"uint8\")\n",
    "        label = tf.strings.reduce_join(num_to_char(labels[i])).numpy().decode(\"utf-8-sig\")\n",
    "        ax[i // 4, i % 4].imshow(img[:, :, 0].T, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ocr_model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image (InputLayer)             [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 256, 256, 32  320         ['image[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 128, 128, 32  0           ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv2 (Conv2D)                 (None, 128, 128, 64  18496       ['pool1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool2 (MaxPooling2D)           (None, 64, 64, 64)   0           ['Conv2[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 64, 4096)     0           ['pool2[0][0]']                  \n",
      "                                                                                                  \n",
      " dense1 (Dense)                 (None, 64, 64)       262208      ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 64, 64)       0           ['dense1[0][0]']                 \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 64, 256)     197632      ['dropout_2[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_5 (Bidirectional  (None, 64, 128)     164352      ['bidirectional_4[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " label (InputLayer)             [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dense2 (Dense)                 (None, 64, 1107)     142803      ['bidirectional_5[0][0]']        \n",
      "                                                                                                  \n",
      " ctc_loss (CTCLayer)            (None, 64, 1107)     0           ['label[0][0]',                  \n",
      "                                                                  'dense2[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 785,811\n",
      "Trainable params: 785,811\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # At test time, just return the computed predictions\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    input_img = layers.Input(\n",
    "        shape=(img_width, img_height, 1), name=\"image\", dtype=\"float32\"\n",
    "    )\n",
    "    labels = layers.Input(name=\"label\", shape=(None,), dtype=\"float32\")\n",
    "\n",
    "    # First conv block\n",
    "    x = layers.Conv2D(\n",
    "        32,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv1\",\n",
    "    )(input_img)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool1\")(x)\n",
    "\n",
    "    # Second conv block\n",
    "    x = layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=\"he_normal\",\n",
    "        padding=\"same\",\n",
    "        name=\"Conv2\",\n",
    "    )(x)\n",
    "    x = layers.MaxPooling2D((2, 2), name=\"pool2\")(x)\n",
    "\n",
    "    # We have used two max pool with pool size and strides 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing the output to the RNN part of the model\n",
    "    new_shape = ((img_width // 4), (img_height // 4) * 64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name=\"reshape\")(x)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # RNNs\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = layers.Dense(\n",
    "        len(char_to_num.get_vocabulary()) + 1, activation=\"softmax\", name=\"dense2\"\n",
    "    )(x)\n",
    "\n",
    "    # Add CTC layer for calculating CTC loss at each step\n",
    "    output = CTCLayer(name=\"ctc_loss\")(labels, x)\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_img, labels], outputs=output, name=\"ocr_model_v1\"\n",
    "    )\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam()\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Get the model\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-05 17:35:15.388616: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/_h/gtk6d0ts49v7qzkzs3wq6_100000gn/T/ipykernel_43102/2162554184.py\", line 9, in <cell line: 9>\n      history = model.fit(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1039, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/_h/gtk6d0ts49v7qzkzs3wq6_100000gn/T/ipykernel_43102/2162554184.py\", line 9, in <cell line: 9>\n      history = model.fit(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1039, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [6], [batch]: [3]\n\t [[{{node IteratorGetNext}}]]\n\t [[ocr_model_v1/ctc_loss/mul_1/_50]]\n  (1) INVALID_ARGUMENT:  Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [6], [batch]: [3]\n\t [[{{node IteratorGetNext}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_36034]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiseungmin/Desktop/AIContest/ocr.ipynb 셀 14\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, patience\u001b[39m=\u001b[39mearly_stopping_patience, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     train_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/_h/gtk6d0ts49v7qzkzs3wq6_100000gn/T/ipykernel_43102/2162554184.py\", line 9, in <cell line: 9>\n      history = model.fit(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1039, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\nDetected at node 'IteratorGetNext' defined at (most recent call last):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n      app.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n      await self.process_one()\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n      await dispatch(*args)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n      await result\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n      reply_content = await reply_content\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2880, in run_cell\n      result = self._run_cell(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2935, in _run_cell\n      return runner(coro)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3134, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3337, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3397, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/var/folders/_h/gtk6d0ts49v7qzkzs3wq6_100000gn/T/ipykernel_43102/2162554184.py\", line 9, in <cell line: 9>\n      history = model.fit(\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/Users/jiseungmin/miniforge3/envs/tf/lib/python3.8/site-packages/keras/engine/training.py\", line 1039, in step_function\n      data = next(iterator)\nNode: 'IteratorGetNext'\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [6], [batch]: [3]\n\t [[{{node IteratorGetNext}}]]\n\t [[ocr_model_v1/ctc_loss/mul_1/_50]]\n  (1) INVALID_ARGUMENT:  Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [6], [batch]: [3]\n\t [[{{node IteratorGetNext}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_36034]"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "early_stopping_patience = 10\n",
    "# Add early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=early_stopping_patience, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 200, 50, 1)]      0         \n",
      "                                                                 \n",
      " Conv1 (Conv2D)              (None, 200, 50, 32)       320       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 100, 25, 32)       0         \n",
      "                                                                 \n",
      " Conv2 (Conv2D)              (None, 100, 25, 64)       18496     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 50, 12, 64)        0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 50, 768)           0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 50, 64)            49216     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 50, 64)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 50, 256)          197632    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 50, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 50, 1107)          142803    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 572,819\n",
      "Trainable params: 572,819\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [3], [batch]: [4] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/Users/jiseungmin/Desktop/AIContest/ocr.ipynb 셀 14\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m output_text\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#  Let's check results on some validation samples\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m validation_dataset\u001b[39m.\u001b[39mtake(\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     batch_images \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jiseungmin/Desktop/AIContest/ocr.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     batch_labels \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:766\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    765\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    767\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    768\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    750\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    751\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    752\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    754\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3018\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [3], [batch]: [4] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "# Get the prediction model by extracting layers till the output layer\n",
    "prediction_model = keras.models.Model(\n",
    "    model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output\n",
    ")\n",
    "prediction_model.summary()\n",
    "\n",
    "# A utility function to decode the output of the network\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_length\n",
    "    ]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.strings.reduce_join(num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "#  Let's check results on some validation samples\n",
    "for batch in validation_dataset.take(1):\n",
    "    batch_images = batch[\"image\"]\n",
    "    batch_labels = batch[\"label\"]\n",
    "\n",
    "    preds = prediction_model.predict(batch_images)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "    orig_texts = []\n",
    "    for label in batch_labels:\n",
    "        label = tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "        orig_texts.append(label)\n",
    "\n",
    "    _, ax = plt.subplots(4, 4, figsize=(15, 5))\n",
    "    for i in range(len(pred_texts)):\n",
    "        img = (batch_images[i, :, :, 0] * 255).numpy().astype(np.uint8)\n",
    "        img = img.T\n",
    "        title = f\"Prediction: {pred_texts[i]}\"\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(title)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f05e964b4d2e4afbb91fe932de86bd0523d55968cb2083dd8663aabd8c2c6a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
